import 'dotenv/config'

import { commonAbis, evmDecoder, evmPortalSource } from "@subsquid/pipes/evm";
import { metricsServer } from "@subsquid/pipes/metrics/node";
import {
  chunk,
  drizzleTarget,
} from "@subsquid/pipes/targets/drizzle/node-postgres";
import { drizzle } from "drizzle-orm/node-postgres";
import { formatUnits } from "viem";
import { Network, transfersTable } from "./schemas";
import { getTokenByNetwork, stablecoinList } from "./tokens";

const DB_CONNECTION_STR =
  process.env.DB_CONNECTION_STR ??
  (() => {
    throw new Error("DB_CONNECTION_STR env missing");
  })();

/**
 * The full list of available networks can be found in the link below:
 *
 * https://beta.docs.sqd.dev/en/data/networks
 */
async function erc20TransferPipe(network: Network) {
  await evmPortalSource({
    portal: {
      url: `https://portal.sqd.dev/datasets/${network}`,
    },
    /**
     * With the metrics collector enabled you can run the built-in UI for tracking
     * metrics and progress by running the command
     * ```sh
     * <npx | bunx | pnpm dlx> @sqd-pipes/pipe-ui
     * ```
     */
    metrics: metricsServer(),
  })
    .pipe(
      evmDecoder({
        range: { from: "latest" },
        /**
         *  This property is optional. Leave it empty to index all transfer events emitted
         */
        contracts: stablecoinList[network],
        events: {
          transfers: commonAbis.erc20.events.Transfer,
        },
      })
    )
    .pipe(({ transfers }) =>
      transfers.map((t) => {
        const token = getTokenByNetwork(network, t.contract);
        return {
          tokenSymbol: token.symbol,
          tokenAddress: token.address,
          network,
          blockNumber: t.block.number,
          logIndex: t.rawEvent.logIndex,
          transactionIndex: t.rawEvent.transactionIndex,
          from: t.event.from,
          to: t.event.to,
          rawAmount: t.event.value,
          amount: formatUnits(t.event.value, token.decimals),
          createdAt: new Date(t.timestamp),
        };
      })
    )
    /**
     *  You can also chain pipes to perform additional transformations or validations
     * .pipe(({ transfers }) =>  {})
     */
    .pipeTo(
      /**
       * Pipes SDK also supports Clickhouse for heavy analytical workloads.
       * https://beta.docs.sqd.dev/en/sdk/pipes-sdk/evm.autogenerated/integration-advanced/clickhouse
       */
      drizzleTarget({
        db: drizzle(DB_CONNECTION_STR),
        /**
         * Make sure to include in this array, all table modified in the `onData`
         * function. The Pipes SDK uses this list to execute rollbacks when reorgs
         * are spotted
         */
        tables: [transfersTable],
        onData: async ({ tx, data, ctx }) => {
          /**
           * Postgres have a hard limit of the amount of rows to be added in a single
           * statement, `chunk` ensures the indexer doesn't go over that limit causing
           * the insert to fail
           */
          for (const values of chunk(data)) {
            const span = ctx.profiler.start("Transfer Insert");
            await tx.insert(transfersTable).values(values);
            span.end();
          }
        },
      })
    );
}

void erc20TransferPipe("ethereum-mainnet");
